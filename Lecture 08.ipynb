{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to recommender systems\n",
    "We continue the previous lecture & explain how to put everything together to build a data pipeline!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipeline\n",
    "\n",
    "How can a model predict future data?\n",
    "\n",
    "Previously we have followed these steps:\n",
    "1) Divide data into train and test data\n",
    "2) Scaling: standardization, normalization\n",
    "3) Dimensionality Reduction: PCA, Random Forest\n",
    "4) Learning algorithm: SVM, k-NN, Decision tree...\n",
    "5) Predictive model: predict class labels\n",
    "\n",
    "Now we will only have:\n",
    "* pipeline.fit -> pipeline.predict\n",
    "* *Gets raw data as input and returns valuable insight as output*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cancer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df = pd.read_csv('Data/cancer_data.csv')\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the class labels from their string (M B) into integers (1 0)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = cancer_df.iloc[:,2:].values\n",
    "y = cancer_df.iloc[:,1].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y_enc = le.transform(['M', 'B'])\n",
    "\n",
    "print('[M B] labels ->', y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Train - test split (80/20)\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pre-processing \n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# # Dimension reduction\n",
    "# from sklearn.decomposition import PCA\n",
    "# # Classification\n",
    "# from sklearn.linear_model import LogisticRegression \n",
    "# from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('scl', StandardScaler()), \n",
    "                    ('pca', PCA(n_components=2)),\n",
    "                    ('clf', LogisticRegression())])\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred = pipe_lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_lr,\n",
    "                         X=X_train, \n",
    "                         y=y_train,\n",
    "                         cv=5,\n",
    "                         n_jobs=1)\n",
    "\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score, make_scorer, recall_score, precision_score\n",
    "\n",
    "print('Accuracy: %.3f' % pipe_lr.score(X_test, y_test))\n",
    "print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
    "print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
    "print('F1: %.3f' % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confmat = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix:\\n', confmat)\n",
    "\n",
    "# [[TP][FN]\n",
    "#  [FP][FP]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.5)\n",
    "\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i,j],\n",
    "                va = 'center', \n",
    "                ha = 'center')\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: Non-linear data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the new circular data\n",
    "circle_df = pd.read_csv('Data/circle_data_v2.csv')\n",
    "circle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming class labels [-1 1] -> [0 1]\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = circle_df.loc[:,'x0':'x1'].values\n",
    "y = circle_df.loc[:,'y'].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split (70/30)\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pre-processing:\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# # Dimension reduction:\n",
    "# from sklearn.decomposition import PCA\n",
    "# # Classification:\n",
    "# from sklearn.svm import SVC \n",
    "# from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc = Pipeline([('scl', StandardScaler()), \n",
    "                    ('pca', PCA(n_components=2)),\n",
    "                    ('clf', SVC())])\n",
    "\n",
    "pipe_svc.fit(X_train, y_train)\n",
    "y_pred = pipe_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing 5-fold Cross validation \n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_svc, \n",
    "                         X=X_train, \n",
    "                         y=y_train,\n",
    "                         cv=5, \n",
    "                         n_jobs=1)\n",
    "\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score, make_scorer, recall_score, precision_score\n",
    "\n",
    "print('Accuracy: %.3f' % pipe_svc.score(X_test, y_test))\n",
    "print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
    "print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
    "print('F1: %.3f' % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix:\\n', confmat)\n",
    "\n",
    "# Plotting confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.5)\n",
    "\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i,j],\n",
    "                va = 'center', \n",
    "                ha = 'center')\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender Systems \n",
    "\n",
    "Data -> [Predictive Model] -> Interface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision making - Aspect model**\n",
    "How do we make choices in life?\n",
    "* A - Attributes\n",
    "* S - Social Influence\n",
    "* P - Policies\n",
    "* E - Experience\n",
    "* C - Consequences\n",
    "* T - Trial and error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of Recommender Systems**\n",
    "* Content-based filtering (CBF)\n",
    "* Collaborative Filtering (CF)\n",
    "* Hybrid (CBF+CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data \n",
    "genre_df = pd.read_csv('Data/movies-genres.csv')\n",
    "genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating moveie vector based on their genre\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(genre_df.loc[:,'genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_array = count_matrix.toarray()\n",
    "print(count_array[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building similarity matrix for all movies\n",
    "\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sim_matrix = cosine_similarity(count_matrix, count_matrix)\n",
    "sim_matrix[0:5,0:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a simple recommender function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_recommender(data_frame, movie_id, sim_matrix):\n",
    "    # Similarity of all movies\n",
    "    sim_df = pd.DataFrame(sim_matrix[movie_id], \n",
    "                          columns = ['similarity'])\n",
    "    # Building a movie_rec\n",
    "    # a dataframe with <title>, <similarity> columns\n",
    "    movie_titles = data_frame.loc[:,'title']\n",
    "    movie_rec = pd.concat([sim_df, movie_titles], axis = 1)\n",
    "    \n",
    "    # Sorting movie_rec according to genre similarity \n",
    "    movie_rec=movie_rec.sort_values(by = ['similarity'], ascending=False)\n",
    "\n",
    "    # Top 10 recommendation based on genre similarity\n",
    "    return movie_rec.iloc[1:10,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function \n",
    "movie_id = 8 # Select the movie ID of a movie\n",
    "\n",
    "# Enter the parameters of the function:\n",
    "simple_recommender(data_frame=genre_df,\n",
    "                   movie_id= movie_id,\n",
    "                   sim_matrix=sim_matrix )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pandas_datareader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
