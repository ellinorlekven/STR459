{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Predictive Models (part 2)\n",
    "Supervised learning with classification and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "                    alpha=0.8, c=cmap(idx),\n",
    "                    marker=markers[idx], label=cl)\n",
    "\n",
    "    # highlight test samples\n",
    "    if test_idx:\n",
    "        # plot all samples\n",
    "        if not versiontuple(np.__version__) >= versiontuple('1.9.0'):\n",
    "            X_test, y_test = X[list(test_idx), :], y[list(test_idx)]\n",
    "            warnings.warn('Please update to NumPy 1.9.0 or newer')\n",
    "        else:\n",
    "            X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='',\n",
    "                    alpha=1.0,\n",
    "                    linewidths=1,\n",
    "                    marker='o',\n",
    "                    s=55, label='test set')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlin_df = pd.read_csv('Data/nonlinear_data.csv')\n",
    "nonlin_df.head()\n",
    "\n",
    "X = nonlin_df.loc[:,['x0', 'x1']].values\n",
    "y = nonlin_df.loc[:,'y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion = 'entropy', max_depth=3)\n",
    "\n",
    "tree.fit(X,y)\n",
    "\n",
    "plot_decision_regions(X, y, classifier=tree)\n",
    "plt.legend()\n",
    "plt.xlabel('X0')\n",
    "plt.ylabel('X1')\n",
    "plt.title('Decision Tree classifier')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (RF)\n",
    "an ensemble of decision trees. Ensemble of learning: combining weak learners to build a strong learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(criterion='entropy', \n",
    "                                n_estimators=10, # number of trees in forest\n",
    "                                n_jobs=2)\n",
    "\n",
    "forest.fit(X, y)\n",
    "\n",
    "plot_decision_regions(X, y, classifier=forest)\n",
    "plt.legend()\n",
    "plt.xlabel('X0')\n",
    "plt.ylabel('X1')\n",
    "plt.title('Decision Tree classifier')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoe_df = pd.DataFrame([['Green', 50.50],\n",
    "                        ['Red', 93.50],\n",
    "                        ['Blue', 35.30]])\n",
    "\n",
    "shoe_df.columns = ['Color', 'Price']\n",
    "shoe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = shoe_df.values\n",
    "\n",
    "color_le = LabelEncoder()\n",
    "X[:,0] = color_le.fit_transform(X[:,0])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct = ColumnTransformer([('Color', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feauture engineering (cancer data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cancer_df = pd.read_csv('Data/cancer_data.csv')\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# Tranforming class labels to 0 and 1 \n",
    "X = cancer_df.iloc[:,2:].values\n",
    "y = cancer_df.iloc[:,1].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print('[M B] labels ->', le.transform(['M', 'B']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1000, # number of decicion trees\n",
    "                                n_jobs = 5)\n",
    "\n",
    "forest.fit(X, y)\n",
    "\n",
    "feat_labels = cancer_df.columns[1:]\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances[::-1])\n",
    "\n",
    "for f in range(5):\n",
    "    print('%2d) %-*s %f' % (f + 1,\n",
    "                            30, \n",
    "                            feat_labels[indices[f]],\n",
    "                            importances[indices[f]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the importance of the features\n",
    "\n",
    "plt.title('Feature importance')\n",
    "plt.bar(range(X.shape[1]),\n",
    "        importances[indices], \n",
    "        color = 'blue',\n",
    "        align = 'center')\n",
    "\n",
    "plt.xticks(range(X.shape[1]),\n",
    "           feat_labels[indices],\n",
    "           rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabete_df = pd.read_csv('Data/diabetes_dataset.csv')\n",
    "diabete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabete_df.iloc[:,:-2].values\n",
    "y = diabete_df.iloc[:,-1].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print('[tested_positive tested_negative] --> labels', le.transform(['tested_positive', 'tested_negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a RandomForest model and print the top 5 most important features\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X,y)\n",
    "\n",
    "feat_labels = diabete_df.columns[1:]\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(5):\n",
    "    print('%2d) %-*s %f' % (f + 1,\n",
    "                            30, \n",
    "                            feat_labels[indices[f]],\n",
    "                            importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the importance of the features\n",
    "\n",
    "plt.title('Feature importance')\n",
    "plt.bar(range(X.shape[1]),\n",
    "        importances[indices], \n",
    "        color = 'blue',\n",
    "        align = 'center')\n",
    "\n",
    "plt.xticks(range(X.shape[1]),\n",
    "           feat_labels[indices],\n",
    "           rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression \n",
    "Supervised learning - predicting a continuous variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house = pd.read_csv('Data/df_house_ma.csv')\n",
    "df_house.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_plot = ['LSTAT', 'INDUS', 'NOX', 'RM', 'MEDV']\n",
    "pd.plotting.scatter_matrix(df_house.loc[:,col_to_plot],\n",
    "                           figsize=(10,10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_house[col_to_plot].values.T\n",
    "cm = np.corrcoef(data)\n",
    "cm = np.around(cm, decimals = 2)\n",
    "print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = plt.imshow(cm, cmap='bwr')\n",
    "plt.xticks(np.arange(5), col_to_plot)\n",
    "plt.yticks(np.arange(5), col_to_plot)\n",
    "cbar = fig.colorbar(ax)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_house[['RM']].values\n",
    "y = df_house['MEDV'].values # Choosing the columns\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X_std = sc_x.fit_transform(X) # Standardizing values \n",
    "y_std = sc_y.fit_transform(y[:,np.newaxis]) # Standardizing values\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "slr = LinearRegression()\n",
    "slr.fit(X_std, y_std)\n",
    "y_pred = slr.predict(X_std)\n",
    "\n",
    "plt.scatter(X_std, y_std, c ='blue')\n",
    "plt.plot(X_std, y_pred, c='red')\n",
    "plt.xlabel('# rooms [RM]')\n",
    "plt.ylabel('price [MEDV]')\n",
    "plt.title('Linear Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.around(slr.intercept_[0], decimals=2)\n",
    "w1 = np.around(slr.coef_[0][0], decimals=2)\n",
    "print(f'y = {w0} + {w1} * X')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz\n",
    "The company asks us to analyze the dataset and:\n",
    "* compute the correlation between features(correlation analysis)\n",
    "* build a linear regression model\n",
    "* predict the revenue of these upcoming films in [$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv('Data/movie-data-clean.csv')\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_ = 'budget', 'vote_count', 'revenue'\n",
    "pd.plotting.scatter_matrix(movie_df.loc[:,columns_],\n",
    "                           figsize=(8,8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = movie_df[columns_].values.T\n",
    "# cm = np.corrcoef(data)\n",
    "# cm = np.around(cm, decimals=2)\n",
    "# print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = plt.imshow(cm,cmap='bwr')\n",
    "len_ = len(columns_)\n",
    "plt.xticks(np.arange(len_), columns_)\n",
    "plt.yticks(np.arange(len_), columns_)\n",
    "cbar = fig.colorbar(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se more in slides"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moon_df = pd.read_csv('Data/moon_data.csv')\n",
    "moon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = moon_df.loc[:,['x0','x1']].values\n",
    "y = moon_df.loc[:, 'y'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VIzualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[y==1,0],\n",
    "            X[y==1,1],\n",
    "            c= 'b', marker = 'x',\n",
    "            label = 'class label 1')\n",
    "plt.scatter(X[y==-1,0],\n",
    "            X[y==-1,1],\n",
    "            c= 'r', marker = 's',\n",
    "            label = 'class label 2')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('X0')\n",
    "plt.ylabel('X1')\n",
    "plt.title('Moon dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decision Tree Classifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "\n",
    "tree.fit(X,y)\n",
    "plot_decision_regions(X, y, classifier=tree)\n",
    "plt.legend()\n",
    "plt.xlabel('X0')\n",
    "plt.ylabel('X1')\n",
    "plt.title('Decision Tree')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(criterion='entropy', n_estimators=10, n_jobs=2)\n",
    "\n",
    "forest.fit(X, y)\n",
    "\n",
    "plot_decision_regions(X, y, classifier=forest)\n",
    "plt.legend()\n",
    "plt.xlabel('X0')\n",
    "plt.ylabel('X1')\n",
    "plt.title('Random Forest Classifier')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=10000, n_jobs=5)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=forest, \n",
    "                         X = X_train, \n",
    "                         y = y_train,\n",
    "                         cv = 5, \n",
    "                         n_jobs= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score, make_scorer, recall_score, precision_score\n",
    "\n",
    "print('Accuracy: %.3f' % forest.score(X_test, y_test))\n",
    "print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
    "print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
    "print('F1: %.3f' % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
