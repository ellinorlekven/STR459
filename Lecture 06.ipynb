{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Predictive Models (part 1)\n",
    "Supervised learning with classification and regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions p.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from Data.Perceptron import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(9)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.where(x<2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.where(x == 0, 'YES', 'no')\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split with sklearn p.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=my_test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('size of train set [%]:', X_train.size / X.size)\n",
    "print('size of test set [%]:', X_test.size / X.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X,y,my_test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=my_test_size)\n",
    "    \n",
    "    plt.hist(X[:,0])\n",
    "    plt.hist(X_train[:,0])\n",
    "    plt.hist(X_test[:,0])\n",
    "    plt.legend(['Full set', 'Train set', 'Test set'])\n",
    "    plt.show()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset(X,y,my_test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with plotting p.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = pd.read_csv('Data/iris.data', header = None)\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select setosa ans versicolor\n",
    "y = df_iris.iloc[0:100, 4].values\n",
    "y = np.where(y == 'Iris-setosa', -1, 1)\n",
    "\n",
    "# extract sepal length and petal length\n",
    "X = df_iris.iloc[0:100, [0,2]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:50,0], X[:50,1], \n",
    "            color = 'red', \n",
    "            marker = 'o',\n",
    "            label = 'setosa')\n",
    "plt.scatter(X[50:100,0], X[50:100,1], \n",
    "            color = 'blue', \n",
    "            marker = 'o',\n",
    "            label = 'versicolor')\n",
    "\n",
    "plt.title('Iris dataset')\n",
    "plt.xlabel('Sepal length[cm]')\n",
    "plt.ylabel('Petal length[cm]')\n",
    "plt.legend(loc = 'upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron with sklearn p. 50\n",
    "activation function, objective function and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Perceptron(object):\n",
    "#     def __init__(self, eta, n_iter):\n",
    "#         # Initialization \n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         # fit training data\n",
    "    \n",
    "#     def net_input(self, X):\n",
    "#         # calculate net input\n",
    "    \n",
    "#     def predict(self, X):\n",
    "#         # return class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_dataset(X,y,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppn = Perceptron(eta=0.1)\n",
    "ppn.fit(X_train_std, y_train)\n",
    "y_pred = ppn.predict(X_test_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Misclassified examples: %d'\n",
    "      % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f'\n",
    "      % accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression p.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "my_test_size = 0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=my_test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_std, y_train)\n",
    "y_test_pred = lr.predict_proba(X_test_std)*100\n",
    "y_test_pred = y_test_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True label:\\n', y_test[-5:].reshape(5,1))\n",
    "print('Predicted probabilities:\\n', y_test_pred[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linearly inseparable data p. 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "                    alpha=0.8, c=cmap(idx),\n",
    "                    marker=markers[idx], label=cl)\n",
    "\n",
    "    # highlight test samples\n",
    "    if test_idx:\n",
    "        # plot all samples\n",
    "        if not versiontuple(np.__version__) >= versiontuple('1.9.0'):\n",
    "            X_test, y_test = X[list(test_idx), :], y[list(test_idx)]\n",
    "            warnings.warn('Please update to NumPy 1.9.0 or newer')\n",
    "        else:\n",
    "            X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='',\n",
    "                    alpha=1.0,\n",
    "                    linewidths=1,\n",
    "                    marker='o',\n",
    "                    s=55, label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlin_df = pd.read_csv('Data/nonlinear_data.csv')\n",
    "nonlin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nonlin_df.loc[:,['x0', 'x1']].values\n",
    "y = nonlin_df.loc[:,'y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='rbf', gamma=0.10, C=10.0)\n",
    "svm.fit(X, y)\n",
    "\n",
    "plot_decision_regions(X, y, classifier=svm)\n",
    "plt.legend()\n",
    "plt.legend()\n",
    "plt.xlabel('X0')\n",
    "plt.ylabel('X1')\n",
    "plt.title('SVM Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, \n",
    "                           p=2, \n",
    "                           \n",
    "                           metric = 'minkowski')\n",
    "\n",
    "knn.fit(X,y)\n",
    "\n",
    "plot_decision_regions(X,y, classifier=knn)\n",
    "plt.legend()\n",
    "plt.legend()\n",
    "plt.xlabel('X0')\n",
    "plt.ylabel('X1')\n",
    "plt.title('KNN Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with Circle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle_df = pd.read_csv('Data/circle_data.csv')\n",
    "circle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = circle_df.loc[:,['x0', 'x1']].values\n",
    "y = circle_df.loc[:,'y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[y==1, 0],\n",
    "            X[y==1, 1],\n",
    "            c='b', marker='x',\n",
    "            label = 'class label 1')\n",
    "plt.scatter(X[y==-1, 0],\n",
    "            X[y==-1, 1],\n",
    "            c='r', marker='x',\n",
    "            label = 'class label -1')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('X0')\n",
    "plt.ylabel('X1')\n",
    "plt.title('Moon dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='rbf', gamma=0.40, C=10.0)\n",
    "svm.fit(X, y)\n",
    "\n",
    "plot_decision_regions(X,y,classifier=svm)\n",
    "plt.legend()\n",
    "plt.xlabel('X0')\n",
    "plt.ylabel('X1')\n",
    "plt.title('SVM Classifier')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, \n",
    "                           p=2, \n",
    "                           metric='minkowski') # Generalization of Edulidean \n",
    "# & Manhattan distance \n",
    "\n",
    "svm = SVC(kernel='rbf', gamma=0.40, C=10.0)\n",
    "svm.fit(X, y)\n",
    "\n",
    "plot_decision_regions(X,y,classifier=svm)\n",
    "plt.legend()\n",
    "plt.xlabel('X0')\n",
    "plt.ylabel('X1')\n",
    "plt.title('KNN classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home Exercise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
