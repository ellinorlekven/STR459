{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis (part 1)\n",
    "Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/example_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminates rows with NA-values\n",
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminates coulmns with NA-values\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops the rows where all of its values are NaN\n",
    "df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it only drops the rows where NaN appear in the column ‘D’\n",
    "\n",
    "df.dropna(subset=['D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car = pd.read_csv('Data/car_data.csv')\n",
    "df_car['num-of-doors'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_car['engine-size'].mean()\n",
    "df_car = df_car.replace('?',mean)\n",
    "df_car['engine-size'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing NaN with imputer\n",
    "\n",
    "my_miss = np.NaN\n",
    "my_stra = 'mean'\n",
    "\n",
    "imputer = SimpleImputer(missing_values=my_miss, strategy=my_stra)\n",
    "\n",
    "imputer = imputer.fit(df)\n",
    "imputed_data = imputer.transform(df.values)\n",
    "imputed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.NaN, strategy='most_frequent')\n",
    "\n",
    "imputer = imputer.fit(df)\n",
    "imputed_data = imputer.transform(df.values)\n",
    "imputed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car.hist(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which roww has most missing values?\n",
    "df_car.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_before=df_car.loc[:,'normalized-losses'].mean()\n",
    "std_before=df_car.loc[:,'normalized-losses'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_car=df_car.replace(np.NAN,mean_before)\n",
    "mean_after=df_car.loc[:,\"normalized-losses\"].mean()\n",
    "std_after=df_car.loc[:,\"normalized-losses\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('mean before:',mean_before,'--->', \\\n",
    "'mean_after:',mean_after)\n",
    "\n",
    "print('std before:',std_before,'--->', \\\n",
    "'std_after:',std_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"house age [y]\": [10,15,20,25,30,35,40], \n",
    "        \"city 1 [m]\": [1,0.5,0.3,0.2,0.1,0.09,0.08],\n",
    "        \"city 2 [m]\": [35, 30, 25, 20, 15, 10,  5],\n",
    "        \"city 3 [m]\": [10 ,9.9, 9.8, 9.6, 9.3, 9.1, 9.05],\n",
    "        \"city 4 [m]\": [15 ,14.9, 14.8, 14.6, 14.3, 14.1, 14]}\n",
    "\n",
    "house_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 4\n",
    "plt.bar(house_df.iloc[:,0], house_df.iloc[:,1], width)\n",
    "plt.xlabel('house age [y]')\n",
    "plt.ylabel('city 1 [m]')\n",
    "plt.title('House cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df.loc[:,'city 1 [m]':'city 4 [m]'].plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0 \n",
    "sigma = 1\n",
    "rand_data = np.random.normal(mu, sigma, size=1000)\n",
    "df_rand = pd.DataFrame({'rand1':rand_data})\n",
    "df_rand.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car.boxplot(column=['peak-rpm','price'])\n",
    "df_car.hist(column=['price','peak-rpm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files \n",
    "# file = open(“filename”, “mode”)\n",
    "# file.read()\n",
    "# file.close()\n",
    "\n",
    "# ‘r’ – read mode\n",
    "# ‘w’ – write mode\n",
    "# ‘a’ – append mode\n",
    "# ‘r+’ – special read and write mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files \n",
    "with open('Data/house_df.txt') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrtiting files\n",
    "file = open(\"house_df.txt\", \"w\") \n",
    "file.write('Hello World!')\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_write_75char(name):\n",
    "    file1 = open(name, 'r')\n",
    "    html_content = file1.read()\n",
    "    file1.close()\n",
    "    file2 = open('html_to_text.txt', 'w')\n",
    "    file2.write(html_content[:75])\n",
    "    file2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function \n",
    "read_write_75char('Data/ParseMe.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://api.github.com/user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.headers['content-type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/title/tt0052357/reviews'\n",
    "response = requests.get(url=url)\n",
    "print(response.text[0:130])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_containers = html_soup.find_all('div', class_ = 'text show-more__control')\n",
    "print(type(movie_containers))\n",
    "print(len(movie_containers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_containers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('Data/ParseMe.html', 'r')\n",
    "html_doc = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_links(html_document=html_doc):\n",
    "    html_soup = BeautifulSoup(html_document, 'html.parser')\n",
    "    for link in html_soup.find_all('a'):\n",
    "        print(link.get('href'))\n",
    "\n",
    "# Not filling the function with any parameter because it is already defined\n",
    "parse_links()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie = pd.read_csv('Data/movie_dataset.csv')\n",
    "df_movie.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "review1 = df_movie.loc[0, 'review']\n",
    "review2 = df_movie.loc[1, 'review']\n",
    "review3 = df_movie.loc[2, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(basic_tokenizer(review1))\n",
    "print(basic_tokenizer(review2))\n",
    "print(basic_tokenizer(review3))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tokenizer(text):\n",
    "    tokens = nltk.word_tokenize(text, preserve_line=True)\n",
    "    return tokens\n",
    "\n",
    "# review1 = df_movie.loc[0, 'review']\n",
    "# review2 = df_movie.loc[1, 'review']\n",
    "# review3 = df_movie.loc[2, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nltk_tokenizer(review1))\n",
    "print(nltk_tokenizer(review2))\n",
    "print(nltk_tokenizer(review3))\n",
    "# returns tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = nltk.corpus.stopwords.words('english')\n",
    "print(stop[0:5])\n",
    "print(len(stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_wo_stopword(text):\n",
    "    tokens = nltk.word_tokenize(text, preserve_line=True)\n",
    "    no_stops = [tok for tok in tokens if tok not in stop]\n",
    "    return no_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokens_wo_stopword(review1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder: List comprehenstion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(review1, preserve_line=True)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the same:\n",
    "# [expression for item in list if condition]\n",
    "\n",
    "# for item in list: \n",
    "#     if condition: \n",
    "#         expression\n",
    "\n",
    "lst_comp = [tok for tok in tokens if tok not in stop]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization - Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: \n",
    "# U.S.A. should be matched with USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.stem.porter.PorterStemmer()\n",
    "def porter_stemmer(text):\n",
    "    tokens = basic_tokenizer(text)\n",
    "    return [porter.stem(tok) for tok in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(porter_stemmer(review1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def porter_stemmer_wo_stops(text):\n",
    "    tokens = basic_tokenizer(text)\n",
    "    return [porter.stem(tok) for tok in tokens if tok not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(porter_stemmer_wo_stops(review1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization - Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_lemmatizer(text):\n",
    "    tokens = basic_tokenizer(text)\n",
    "    lemma = nltk.WordNetLemmatizer()\n",
    "    return [lemma.lemmatize(tok) for tok in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nltk_lemmatizer(review1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_lemmatizer_wo_stops(text):\n",
    "    tokens = basic_tokenizer(text)\n",
    "    lemma = nltk.WordNetLemmatizer()\n",
    "    return [lemma.lemmatize(tok) for tok in tokens if tok not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nltk_lemmatizer_wo_stops(review1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization - Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(ngram_range=(1,3))\n",
    "docs = np.array(['The sun is shining',                              # Document 1\n",
    "                 'The weather is sweet',                            # Document 2\n",
    "                 'The sun is shining and the weather is sweet'])    # Document 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = count.fit_transform(docs)\n",
    "print('Vocabular:', count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in count.vocabulary_.keys():\n",
    "    print(str(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_array = bag.toarray()\n",
    "bag_array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cos_sim(array1, array2):\n",
    "    cos_sim = 1-spatial.distance.cosine(array1,array2)\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cos_sim(bag_array[0], bag_array[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cos_sim_all(my_array):\n",
    "    n_rows = my_array.shape[0]\n",
    "    cos_sim_array = np.zeros((n_rows,n_rows))\n",
    "    for row1 in range (n_rows):\n",
    "        for row2 in range (n_rows):\n",
    "            cos_sim_array[row1, row2] = compute_cos_sim(my_array[row1,:], my_array[row2,:])\n",
    "    return cos_sim_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comssim_values = compute_cos_sim_all(bag_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.imshow(comssim_values, cmap = 'winter')\n",
    "cbar = fig.colorbar(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
